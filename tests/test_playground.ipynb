{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cae4fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:23:33 - __main__ - INFO - Logger kustom berhasil di-setup dan didapatkan untuk notebook.\n",
      "2025-06-04 21:23:33 - __main__ - INFO - Fungsi 'extract_features' dari feature_extractor.py berhasil diimpor.\n",
      "2025-06-04 21:23:33 - __main__ - INFO - Setup awal tahap 1 notebook untuk inferensi URL tunggal selesai.\n",
      "2025-06-04 21:23:33 - __main__ - INFO - Path model yang akan digunakan: d:\\Capstone\\ML - Phishing Detection\\Phishing-Detection\\src\\models\\model_checkpoints_recall_focused\\best_recall_model.keras\n",
      "2025-06-04 21:23:33 - __main__ - INFO - Path preprocessor (file objek terpisah): Tidak digunakan\n",
      "2025-06-04 21:23:33 - __main__ - INFO - Setup awal tahap 2 notebook (path) untuk inferensi URL tunggal selesai.\n"
     ]
    }
   ],
   "source": [
    "# Sel 1: Impor Global, Pengaturan Path, Konfigurasi Logger, Impor Fungsi Fitur\n",
    "\n",
    "# Impor Global yang Mungkin Diperlukan di Seluruh Notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging # Impor logging standar\n",
    "from typing import Optional, Callable, Any, Union, List, Tuple # Pastikan semua type hints yang akan digunakan ada di sini\n",
    "\n",
    "# --- 1. Pengaturan Path ---\n",
    "# Sesuaikan ini berdasarkan lokasi notebook Anda relatif terhadap root proyek\n",
    "# Jika notebook Anda ada di 'PROJECT_ROOT/notebooks/':\n",
    "project_root_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# Jika notebook Anda ada di 'PROJECT_ROOT/src/models/' (seperti models_playground.ipynb Anda):\n",
    "# project_root_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "if project_root_path not in sys.path:\n",
    "    sys.path.append(project_root_path)\n",
    "    # Pesan ini hanya akan muncul sekali jika path baru ditambahkan\n",
    "    print(f\"Path proyek ditambahkan: {project_root_path}\")\n",
    "\n",
    "\n",
    "# --- 2. Impor dan Konfigurasi Logger ---\n",
    "try:\n",
    "    from src.utils.logger import setup_logging, get_logger\n",
    "    # Panggil setup_logging SEKALI SAJA per sesi kernel notebook.\n",
    "    if not logging.getLogger().hasHandlers(): # Cek jika root logger belum punya handler\n",
    "         setup_logging(log_level=logging.INFO) # Atur level sesuai kebutuhan (misal: INFO atau DEBUG)\n",
    "    logger = get_logger(__name__) # Mendapatkan logger untuk notebook ini\n",
    "    logger.info(\"Logger kustom berhasil di-setup dan didapatkan untuk notebook.\")\n",
    "except ImportError:\n",
    "    # Fallback ke basic config jika modul logger kustom tidak ditemukan\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__) # Mendapatkan logger default\n",
    "    logger.warning(\"Menggunakan basicConfig untuk logger karena src.utils.logger tidak ditemukan atau error impor.\")\n",
    "except Exception as e:\n",
    "    # Fallback jika ada error lain saat setup logger kustom\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.error(f\"Error saat setup logger kustom: {e}. Menggunakan basicConfig.\", exc_info=True)\n",
    "\n",
    "\n",
    "# --- 3. Impor Fungsi Ekstraksi Fitur dari Modul Anda ---\n",
    "try:\n",
    "    from src.features.feature_extractor import extract_features # Ini adalah nama fungsi dari file Anda\n",
    "    logger.info(\"Fungsi 'extract_features' dari feature_extractor.py berhasil diimpor.\")\n",
    "except ImportError:\n",
    "    logger.critical(\"GAGAL mengimpor 'extract_features' dari src.features.feature_extractor.\")\n",
    "    logger.critical(\"Pastikan sys.path sudah benar, file ada, dan tidak ada error syntax di feature_extractor.py.\")\n",
    "    logger.critical(\"Inferensi TIDAK AKAN BEKERJA DENGAN BENAR tanpa fungsi ekstraksi fitur yang valid.\")\n",
    "    # Definisikan placeholder HANYA agar sisa notebook bisa dijalankan tanpa NameError,\n",
    "    # TAPI ini TIDAK akan menghasilkan prediksi yang benar.\n",
    "    def extract_features(url_string: str) -> Optional[list]:\n",
    "        logger.error(\"!!! MENGGUNAKAN FUNGSI 'extract_features' PLACEHOLDER !!! Hasil prediksi akan SALAH.\")\n",
    "        # GANTI 'num_expected_features' dengan jumlah fitur aktual model Anda\n",
    "        # Berdasarkan feature_extractor.py Anda, tampaknya ada 21 fitur (tanpa fitur WHOIS)\n",
    "        # Jika fitur WHOIS diaktifkan dan valid, jumlahnya bisa lebih banyak.\n",
    "        # Mari kita asumsikan 21 untuk placeholder ini.\n",
    "        num_expected_features = 21 # GANTI INI jika jumlah fitur berbeda!\n",
    "        logger.warning(f\"Placeholder mengembalikan {num_expected_features} fitur acak.\")\n",
    "        return list(np.random.rand(num_expected_features)) if url_string else None\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error tak terduga saat mengimpor 'extract_features': {e}\", exc_info=True)\n",
    "    def extract_features(url_string: str) -> Optional[list]:\n",
    "        logger.error(f\"!!! MENGGUNAKAN FUNGSI 'extract_features' PLACEHOLDER karena error impor: {e} !!! Hasil prediksi akan SALAH.\")\n",
    "        num_expected_features = 21 # GANTI INI!\n",
    "        logger.warning(f\"Placeholder mengembalikan {num_expected_features} fitur acak.\")\n",
    "        return list(np.random.rand(num_expected_features)) if url_string else None\n",
    "\n",
    "\n",
    "logger.info(\"Setup awal tahap 1 notebook untuk inferensi URL tunggal selesai.\") # Pesan log yang lebih spesifik\n",
    "\n",
    "# --- 4. Konfigurasi Path untuk Model dan Preprocessor ---\n",
    "# Path untuk Model\n",
    "MODEL_DIR_RELATIVE_TO_SRC = Path(\"models\") / \"model_checkpoints_recall_focused\"\n",
    "MODEL_DIR_ABSOLUTE = Path(project_root_path) / \"src\" / MODEL_DIR_RELATIVE_TO_SRC # Model ada di dalam src\n",
    "MODEL_NAME = \"best_recall_model.keras\" # Ganti dengan nama model terbaik Anda\n",
    "SAVED_MODEL_PATH = MODEL_DIR_ABSOLUTE / MODEL_NAME\n",
    "\n",
    "# Path untuk Preprocessor\n",
    "# Karena \"preprocessor\" Anda adalah logika dalam feature_extractor.py (yang sudah diimpor sebagai fungsi),\n",
    "# kita tidak memerlukan path ke file preprocessor terpisah.\n",
    "PREPROCESSOR_PATH = None \n",
    "# Tidak perlu warning di sini karena kita sudah mengklarifikasi bahwa feature_extractor adalah preprocessornya.\n",
    "# Jika Anda *memutuskan* untuk menambahkan scaler terpisah nanti, baru PREPROCESSOR_PATH ini diisi.\n",
    "\n",
    "logger.info(f\"Path model yang akan digunakan: {SAVED_MODEL_PATH}\")\n",
    "logger.info(f\"Path preprocessor (file objek terpisah): {'Tidak digunakan' if PREPROCESSOR_PATH is None else PREPROCESSOR_PATH}\")\n",
    "logger.info(\"Setup awal tahap 2 notebook (path) untuk inferensi URL tunggal selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee464ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:23:36 - __main__ - INFO - Mencoba memuat model dari: d:\\Capstone\\ML - Phishing Detection\\Phishing-Detection\\src\\models\\model_checkpoints_recall_focused\\best_recall_model.keras\n",
      "2025-06-04 21:23:36 - __main__ - INFO - Model berhasil dimuat.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,413</span> (130.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,413\u001b[0m (130.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,137</span> (43.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,137\u001b[0m (43.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,276</span> (87.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,276\u001b[0m (87.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 21:23:36 - __main__ - INFO - Tidak ada path preprocessor yang ditentukan atau preprocessor tidak digunakan.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# --- Memuat Model ---\n",
    "logger.info(f\"Mencoba memuat model dari: {SAVED_MODEL_PATH}\")\n",
    "loaded_model = None # Inisialisasi sebagai None\n",
    "try:\n",
    "    if SAVED_MODEL_PATH.exists(): # Pastikan file model ada\n",
    "        loaded_model = keras.models.load_model(SAVED_MODEL_PATH)\n",
    "        logger.info(\"Model berhasil dimuat.\")\n",
    "        loaded_model.summary() # Tampilkan ringkasan model untuk verifikasi\n",
    "    else:\n",
    "        logger.error(f\"File model tidak ditemukan di: {SAVED_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Gagal memuat model dari {SAVED_MODEL_PATH}: {e}\", exc_info=True)\n",
    "\n",
    "# --- Memuat Preprocessor (Scaler/Encoder) jika digunakan saat training ---\n",
    "preprocessor = None # Inisialisasi sebagai None\n",
    "# Pastikan PREPROCESSOR_PATH sudah didefinisikan di sel sebelumnya (bisa None jika tidak ada)\n",
    "if PREPROCESSOR_PATH and Path(PREPROCESSOR_PATH).exists():\n",
    "    try:\n",
    "        import joblib # Pastikan joblib terinstal jika Anda menggunakannya\n",
    "        preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "        logger.info(f\"Preprocessor berhasil dimuat dari {PREPROCESSOR_PATH}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Gagal memuat preprocessor dari {PREPROCESSOR_PATH}: {e}\", exc_info=True)\n",
    "elif PREPROCESSOR_PATH: # Jika path diset tapi file tidak ada\n",
    "     logger.warning(f\"File preprocessor tidak ditemukan di {PREPROCESSOR_PATH}. Melanjutkan tanpa preprocessor.\")\n",
    "else:\n",
    "    logger.info(\"Tidak ada path preprocessor yang ditentukan atau preprocessor tidak digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfbe7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sel 3: Fungsi untuk Inferensi URL Tunggal\n",
    "\n",
    "# (Pastikan 'extract_features' sudah diimpor dari src.features.feature_extractor di Sel 1)\n",
    "# (Pastikan 'logger' sudah diinisialisasi dari Sel 1)\n",
    "# (Pastikan 'Optional', 'Callable', 'Any', 'Tuple' sudah diimpor dari 'typing' di Sel 1)\n",
    "# (Pastikan 'np' dari 'numpy' dan 'keras' dari 'tensorflow' sudah diimpor di Sel 1 atau Sel 2)\n",
    "\n",
    "def predict_url_type(url_string: str, model: keras.Model,\n",
    "                     # 'extract_features' akan digunakan langsung dari impor global\n",
    "                     preprocessor_obj: Optional[Any] = None,\n",
    "                     threshold: float = 0.5) -> Tuple[Optional[str], Optional[float]]:\n",
    "    \"\"\"\n",
    "    Menerima URL, mengekstrak fitur, melakukan pra-pemrosesan (jika ada), membuat prediksi,\n",
    "    dan mengembalikan tipe prediksi beserta probabilitasnya.\n",
    "\n",
    "    Args:\n",
    "        url_string (str): URL yang akan diprediksi.\n",
    "        model (keras.Model): Model Keras yang sudah dilatih dan dimuat.\n",
    "        preprocessor_obj (Optional[Any]): Objek preprocessor (misal, scaler) yang sudah di-fit.\n",
    "                                       Jika None, tidak ada pra-pemrosesan scaler yang diterapkan.\n",
    "        threshold (float): Ambang batas untuk klasifikasi jika output model adalah sigmoid.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Optional[str], Optional[float]]: (tipe_prediksi, probabilitas_phishing)\n",
    "                                                atau (None, None) jika error.\n",
    "    \"\"\"\n",
    "    if not url_string:\n",
    "        logger.warning(\"Input URL kosong.\")\n",
    "        return None, None\n",
    "\n",
    "    logger.info(f\"Memproses URL: {url_string}\")\n",
    "\n",
    "    # 1. Ekstraksi Fitur menggunakan fungsi yang sudah diimpor dari feature_extractor.py\n",
    "    try:\n",
    "        # 'extract_features' Anda mengembalikan list\n",
    "        list_of_features = extract_features(url_string) # Memanggil fungsi yang diimpor dari Sel 1\n",
    "        if list_of_features is None:\n",
    "            logger.error(f\"Ekstraksi fitur mengembalikan None untuk URL: {url_string}\")\n",
    "            return None, None\n",
    "        \n",
    "        # Konversi ke NumPy array float32\n",
    "        features_1d = np.array(list_of_features, dtype=np.float32)\n",
    "        logger.debug(f\"Fitur (1D) diekstrak: {features_1d.shape} -> {features_1d[:5]}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saat ekstraksi fitur untuk URL '{url_string}': {e}\", exc_info=True)\n",
    "        return None, None\n",
    "    \n",
    "    # Validasi jumlah fitur terhadap input model (PENTING!)\n",
    "    if model.input_shape[1] is not None and features_1d.shape[0] != model.input_shape[1]:\n",
    "        logger.error(f\"Jumlah fitur yang diekstrak ({features_1d.shape[0]}) tidak sesuai dengan input yang diharapkan model ({model.input_shape[1]}).\")\n",
    "        return None, None\n",
    "\n",
    "    # 2. Pra-pemrosesan Fitur (jika ada preprocessor)\n",
    "    # Fitur perlu diubah menjadi 2D array (1 sampel, N fitur)\n",
    "    if features_1d.ndim == 1:\n",
    "        features_2d_for_model = features_1d.reshape(1, -1)\n",
    "    else: \n",
    "        logger.warning(f\"Fitur yang diekstrak sudah {features_1d.ndim}D. Diharapkan 1D sebelum reshape.\")\n",
    "        features_2d_for_model = features_1d # Asumsikan sudah (1, N_fitur) jika bukan 1D\n",
    "\n",
    "    if preprocessor_obj:\n",
    "        try:\n",
    "            logger.debug(f\"Menerapkan preprocessor pada fitur shape: {features_2d_for_model.shape}\")\n",
    "            features_processed = preprocessor_obj.transform(features_2d_for_model) # transform() biasanya mengharapkan 2D\n",
    "            logger.debug(\"Preprocessor berhasil diterapkan.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saat menerapkan preprocessor: {e}\", exc_info=True)\n",
    "            return None, None\n",
    "    else:\n",
    "        features_processed = features_2d_for_model # Gunakan fitur apa adanya jika tidak ada preprocessor\n",
    "\n",
    "    logger.debug(f\"Fitur setelah pra-pemrosesan (siap untuk model): {features_processed.shape} -> {features_processed[0, :5]}...\")\n",
    "\n",
    "    # 3. Membuat Prediksi\n",
    "    try:\n",
    "        prediction_proba = model.predict(features_processed) # Input ke model harus 2D\n",
    "        logger.debug(f\"Probabilitas mentah dari model: {prediction_proba}\")\n",
    "\n",
    "        # Interpretasi output model berdasarkan arsitektur output layer\n",
    "        num_output_neurons = model.layers[-1].units\n",
    "        activation_output = model.layers[-1].activation.__name__ # Mendapatkan nama aktivasi\n",
    "\n",
    "        if num_output_neurons == 1 and activation_output == 'sigmoid':\n",
    "            prob_phishing = prediction_proba[0, 0]\n",
    "            predicted_label_int = 1 if prob_phishing > threshold else 0\n",
    "        elif num_output_neurons > 1 and activation_output == 'softmax': # Misal 2 neuron untuk kelas 0 dan 1\n",
    "            predicted_label_int = np.argmax(prediction_proba, axis=1)[0]\n",
    "            prob_phishing = prediction_proba[0, 1] # Asumsi kelas 1 (phishing) adalah indeks 1\n",
    "            # Jika kelas 0 adalah phishing, gunakan prediction_proba[0, 0]\n",
    "        else:\n",
    "            logger.error(f\"Struktur output layer model tidak dikenali (neurons: {num_output_neurons}, activation: {activation_output}). Tidak bisa interpretasi prediksi.\")\n",
    "            return None, None\n",
    "        \n",
    "        # TODO: Sesuaikan label mapping ini dengan definisi kelas Anda\n",
    "        label_mapping = {0: 'Aman', 1: 'Phishing'} \n",
    "        predicted_type = label_mapping.get(predicted_label_int, f\"Label Int Tidak Diketahui: {predicted_label_int}\")\n",
    "        \n",
    "        logger.info(f\"Prediksi untuk '{url_string}': Tipe='{predicted_type}', Prob_Phishing={prob_phishing:.4f} (Threshold: {threshold if num_output_neurons == 1 else 'argmax'})\")\n",
    "        return predicted_type, prob_phishing\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saat membuat prediksi untuk URL '{url_string}': {e}\", exc_info=True)\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b32cfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Mode Inferensi URL Tunggal ---\n",
      "Ketik 'exit' atau 'quit' untuk keluar.\n",
      "2025-06-04 21:23:43 - __main__ - INFO - Memproses URL: https://railway.com/dashboard\n",
      "2025-06-04 21:23:43 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://railway.com/dashboard\n",
      "2025-06-04 21:23:44 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://railway.com/dashboard. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
      "2025-06-04 21:23:44 - __main__ - INFO - Prediksi untuk 'https://railway.com/dashboard': Tipe='Aman', Prob_Phishing=0.0498 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://railway.com/dashboard':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0498\n",
      "URL tidak boleh kosong. Silakan coba lagi.\n",
      "2025-06-04 21:23:49 - __main__ - INFO - Keluar dari mode inferensi.\n"
     ]
    }
   ],
   "source": [
    "# Sel 4: Loop Interaktif untuk Input Pengguna\n",
    "\n",
    "if 'loaded_model' in locals() and loaded_model: # Pastikan model sudah dimuat dari Sel 2\n",
    "    print(\"\\n--- Mode Inferensi URL Tunggal ---\")\n",
    "    print(\"Ketik 'exit' atau 'quit' untuk keluar.\")\n",
    "    while True:\n",
    "        user_url = input(\"\\nMasukkan URL yang ingin Anda periksa: \").strip()\n",
    "        if user_url.lower() in ['exit', 'quit']:\n",
    "            logger.info(\"Keluar dari mode inferensi.\")\n",
    "            break\n",
    "        if not user_url:\n",
    "            print(\"URL tidak boleh kosong. Silakan coba lagi.\")\n",
    "            continue\n",
    "\n",
    "        # Panggil fungsi prediksi dari Sel 3\n",
    "        # 'extract_features' sudah diimpor secara global di Sel 1\n",
    "        # 'preprocessor' adalah objek yang dimuat di Sel 2 (bisa None)\n",
    "        # 'loaded_model' adalah model yang dimuat di Sel 2\n",
    "        \n",
    "        # TODO: Tentukan threshold yang optimal dari eksperimen Anda jika model outputnya sigmoid\n",
    "        prediction_threshold = 0.5 \n",
    "\n",
    "        predicted_type, probability = predict_url_type(\n",
    "            user_url,\n",
    "            loaded_model, \n",
    "            preprocessor_obj=preprocessor, # Akan bernilai None jika tidak ada preprocessor dimuat\n",
    "            threshold=prediction_threshold \n",
    "        )\n",
    "\n",
    "        if predicted_type is not None:\n",
    "            print(f\"--> Hasil Prediksi untuk '{user_url}':\")\n",
    "            print(f\"    Tipe Terdeteksi: {predicted_type}\")\n",
    "            if probability is not None:\n",
    "                print(f\"    Probabilitas (Phishing): {probability:.4f}\")\n",
    "        else:\n",
    "            print(f\"--> Tidak dapat membuat prediksi untuk '{user_url}'. Periksa log untuk detail.\")\n",
    "else:\n",
    "    print(\"Model belum dimuat (variabel 'loaded_model' tidak ditemukan atau None). Jalankan Sel 2 terlebih dahulu.\")\n",
    "    logger.error(\"Inferensi tidak bisa dijalankan karena model belum dimuat.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
