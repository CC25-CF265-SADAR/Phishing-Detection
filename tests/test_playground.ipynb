{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cae4fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:57:15 - __main__ - INFO - Logger kustom berhasil di-setup dan didapatkan untuk notebook.\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Fungsi 'extract_features' dari feature_extractor.py berhasil diimpor.\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Setup awal tahap 1 notebook untuk inferensi URL tunggal selesai.\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Path model yang akan digunakan: h:\\My Drive\\01. COLLEGE\\06. SEM VI\\Studi Independen\\Coding Camp DBS Foundation\\08. Capstone\\Playground 5\\src\\models\\model_checkpoints_recall_focused\\best_recall_model.keras\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Path preprocessor (file objek terpisah): Tidak digunakan\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Setup awal tahap 2 notebook (path) untuk inferensi URL tunggal selesai.\n"
     ]
    }
   ],
   "source": [
    "# Sel 1: Impor Global, Pengaturan Path, Konfigurasi Logger, Impor Fungsi Fitur\n",
    "\n",
    "# Impor Global yang Mungkin Diperlukan di Seluruh Notebook\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging # Impor logging standar\n",
    "from typing import Optional, Callable, Any, Union, List # Pastikan semua type hints yang akan digunakan ada di sini\n",
    "\n",
    "# --- 1. Pengaturan Path ---\n",
    "# Sesuaikan ini berdasarkan lokasi notebook Anda relatif terhadap root proyek\n",
    "# Jika notebook Anda ada di 'PROJECT_ROOT/notebooks/':\n",
    "project_root_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "# Jika notebook Anda ada di 'PROJECT_ROOT/src/models/' (seperti models_playground.ipynb Anda):\n",
    "# project_root_path = os.path.abspath(os.path.join(os.getcwd(), os.pardir, os.pardir))\n",
    "\n",
    "if project_root_path not in sys.path:\n",
    "    sys.path.append(project_root_path)\n",
    "    # Pesan ini hanya akan muncul sekali jika path baru ditambahkan\n",
    "    print(f\"Path proyek ditambahkan: {project_root_path}\")\n",
    "\n",
    "\n",
    "# --- 2. Impor dan Konfigurasi Logger ---\n",
    "try:\n",
    "    from src.utils.logger import setup_logging, get_logger\n",
    "    # Panggil setup_logging SEKALI SAJA per sesi kernel notebook.\n",
    "    if not logging.getLogger().hasHandlers(): # Cek jika root logger belum punya handler\n",
    "         setup_logging(log_level=logging.INFO) # Atur level sesuai kebutuhan (misal: INFO atau DEBUG)\n",
    "    logger = get_logger(__name__) # Mendapatkan logger untuk notebook ini\n",
    "    logger.info(\"Logger kustom berhasil di-setup dan didapatkan untuk notebook.\")\n",
    "except ImportError:\n",
    "    # Fallback ke basic config jika modul logger kustom tidak ditemukan\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__) # Mendapatkan logger default\n",
    "    logger.warning(\"Menggunakan basicConfig untuk logger karena src.utils.logger tidak ditemukan atau error impor.\")\n",
    "except Exception as e:\n",
    "    # Fallback jika ada error lain saat setup logger kustom\n",
    "    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.error(f\"Error saat setup logger kustom: {e}. Menggunakan basicConfig.\", exc_info=True)\n",
    "\n",
    "\n",
    "# --- 3. Impor Fungsi Ekstraksi Fitur dari Modul Anda ---\n",
    "try:\n",
    "    from src.features.feature_extractor import extract_features # Ini adalah nama fungsi dari file Anda\n",
    "    logger.info(\"Fungsi 'extract_features' dari feature_extractor.py berhasil diimpor.\")\n",
    "except ImportError:\n",
    "    logger.critical(\"GAGAL mengimpor 'extract_features' dari src.features.feature_extractor.\")\n",
    "    logger.critical(\"Pastikan sys.path sudah benar, file ada, dan tidak ada error syntax di feature_extractor.py.\")\n",
    "    logger.critical(\"Inferensi TIDAK AKAN BEKERJA DENGAN BENAR tanpa fungsi ekstraksi fitur yang valid.\")\n",
    "    # Definisikan placeholder HANYA agar sisa notebook bisa dijalankan tanpa NameError,\n",
    "    # TAPI ini TIDAK akan menghasilkan prediksi yang benar.\n",
    "    def extract_features(url_string: str) -> Optional[list]:\n",
    "        logger.error(\"!!! MENGGUNAKAN FUNGSI 'extract_features' PLACEHOLDER !!! Hasil prediksi akan SALAH.\")\n",
    "        # GANTI 'num_expected_features' dengan jumlah fitur aktual model Anda\n",
    "        # Berdasarkan feature_extractor.py Anda, tampaknya ada 21 fitur (tanpa fitur WHOIS)\n",
    "        # Jika fitur WHOIS diaktifkan dan valid, jumlahnya bisa lebih banyak.\n",
    "        # Mari kita asumsikan 21 untuk placeholder ini.\n",
    "        num_expected_features = 21 # GANTI INI jika jumlah fitur berbeda!\n",
    "        logger.warning(f\"Placeholder mengembalikan {num_expected_features} fitur acak.\")\n",
    "        return list(np.random.rand(num_expected_features)) if url_string else None\n",
    "except Exception as e:\n",
    "    logger.critical(f\"Error tak terduga saat mengimpor 'extract_features': {e}\", exc_info=True)\n",
    "    def extract_features(url_string: str) -> Optional[list]:\n",
    "        logger.error(f\"!!! MENGGUNAKAN FUNGSI 'extract_features' PLACEHOLDER karena error impor: {e} !!! Hasil prediksi akan SALAH.\")\n",
    "        num_expected_features = 21 # GANTI INI!\n",
    "        logger.warning(f\"Placeholder mengembalikan {num_expected_features} fitur acak.\")\n",
    "        return list(np.random.rand(num_expected_features)) if url_string else None\n",
    "\n",
    "\n",
    "logger.info(\"Setup awal tahap 1 notebook untuk inferensi URL tunggal selesai.\") # Pesan log yang lebih spesifik\n",
    "\n",
    "# --- 4. Konfigurasi Path untuk Model dan Preprocessor ---\n",
    "# Path untuk Model\n",
    "MODEL_DIR_RELATIVE_TO_SRC = Path(\"models\") / \"model_checkpoints_recall_focused\"\n",
    "MODEL_DIR_ABSOLUTE = Path(project_root_path) / \"src\" / MODEL_DIR_RELATIVE_TO_SRC # Model ada di dalam src\n",
    "MODEL_NAME = \"best_recall_model.keras\" # Ganti dengan nama model terbaik Anda\n",
    "SAVED_MODEL_PATH = MODEL_DIR_ABSOLUTE / MODEL_NAME\n",
    "\n",
    "# Path untuk Preprocessor\n",
    "# Karena \"preprocessor\" Anda adalah logika dalam feature_extractor.py (yang sudah diimpor sebagai fungsi),\n",
    "# kita tidak memerlukan path ke file preprocessor terpisah.\n",
    "PREPROCESSOR_PATH = None \n",
    "# Tidak perlu warning di sini karena kita sudah mengklarifikasi bahwa feature_extractor adalah preprocessornya.\n",
    "# Jika Anda *memutuskan* untuk menambahkan scaler terpisah nanti, baru PREPROCESSOR_PATH ini diisi.\n",
    "\n",
    "logger.info(f\"Path model yang akan digunakan: {SAVED_MODEL_PATH}\")\n",
    "logger.info(f\"Path preprocessor (file objek terpisah): {'Tidak digunakan' if PREPROCESSOR_PATH is None else PREPROCESSOR_PATH}\")\n",
    "logger.info(\"Setup awal tahap 2 notebook (path) untuk inferensi URL tunggal selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee464ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:57:15 - __main__ - INFO - Mencoba memuat model dari: h:\\My Drive\\01. COLLEGE\\06. SEM VI\\Studi Independen\\Coding Camp DBS Foundation\\08. Capstone\\Playground 5\\src\\models\\model_checkpoints_recall_focused\\best_recall_model.keras\n",
      "2025-06-02 10:57:15 - __main__ - INFO - Model berhasil dimuat.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,413</span> (130.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,413\u001b[0m (130.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,137</span> (43.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,137\u001b[0m (43.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,276</span> (87.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,276\u001b[0m (87.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:57:15 - __main__ - INFO - Tidak ada path preprocessor yang ditentukan atau preprocessor tidak digunakan.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# --- Memuat Model ---\n",
    "logger.info(f\"Mencoba memuat model dari: {SAVED_MODEL_PATH}\")\n",
    "loaded_model = None # Inisialisasi sebagai None\n",
    "try:\n",
    "    if SAVED_MODEL_PATH.exists(): # Pastikan file model ada\n",
    "        loaded_model = keras.models.load_model(SAVED_MODEL_PATH)\n",
    "        logger.info(\"Model berhasil dimuat.\")\n",
    "        loaded_model.summary() # Tampilkan ringkasan model untuk verifikasi\n",
    "    else:\n",
    "        logger.error(f\"File model tidak ditemukan di: {SAVED_MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Gagal memuat model dari {SAVED_MODEL_PATH}: {e}\", exc_info=True)\n",
    "\n",
    "# --- Memuat Preprocessor (Scaler/Encoder) jika digunakan saat training ---\n",
    "preprocessor = None # Inisialisasi sebagai None\n",
    "# Pastikan PREPROCESSOR_PATH sudah didefinisikan di sel sebelumnya (bisa None jika tidak ada)\n",
    "if PREPROCESSOR_PATH and Path(PREPROCESSOR_PATH).exists():\n",
    "    try:\n",
    "        import joblib # Pastikan joblib terinstal jika Anda menggunakannya\n",
    "        preprocessor = joblib.load(PREPROCESSOR_PATH)\n",
    "        logger.info(f\"Preprocessor berhasil dimuat dari {PREPROCESSOR_PATH}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Gagal memuat preprocessor dari {PREPROCESSOR_PATH}: {e}\", exc_info=True)\n",
    "elif PREPROCESSOR_PATH: # Jika path diset tapi file tidak ada\n",
    "     logger.warning(f\"File preprocessor tidak ditemukan di {PREPROCESSOR_PATH}. Melanjutkan tanpa preprocessor.\")\n",
    "else:\n",
    "    logger.info(\"Tidak ada path preprocessor yang ditentukan atau preprocessor tidak digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfbe7bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# Diasumsikan ini adalah bagian dari Sel 3 atau file utilitas yang diimpor\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 'extract_features' diasumsikan sudah diimpor atau didefinisikan sebelumnya\n",
    "# from src.features.feature_extractor import extract_features # Contoh jika ada di path ini\n",
    "\n",
    "def predict_url_type_with_features(url, model, feature_extractor_func, preprocessor_obj=None, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Memprediksi tipe URL dan mengembalikan fitur yang berkontribusi.\n",
    "\n",
    "    Args:\n",
    "        url (str): URL yang akan diperiksa.\n",
    "        model (object): Model machine learning yang sudah dilatih.\n",
    "        feature_extractor_func (function): Fungsi untuk mengekstrak fitur dari URL.\n",
    "                                          Harus mengembalikan DataFrame pandas.\n",
    "        preprocessor_obj (object, optional): Objek preprocessor (misal, scaler) jika ada. Defaults to None.\n",
    "        threshold (float, optional): Threshold untuk klasifikasi biner jika output sigmoid. Defaults to 0.5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (str, float, list)\n",
    "               - Tipe prediksi ('Phishing', 'Aman', atau 'Error').\n",
    "               - Probabilitas phishing (jika model mendukung dan bukan error).\n",
    "               - Daftar dictionary fitur yang berkontribusi (nama, nilai, kepentingan/bobot).\n",
    "                 Akan kosong jika fitur tidak dapat diekstrak atau model tidak mendukung.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Ekstrak Fitur\n",
    "        features_data = feature_extractor_func(url) # Ubah nama variabel sementara\n",
    "\n",
    "        # Tambahkan pengecekan tipe di sini\n",
    "        if features_data is None:\n",
    "            logger.error(f\"Gagal mengekstrak fitur (None) untuk URL: {url}\")\n",
    "            return \"Error\", None, []\n",
    "        \n",
    "        # Jika feature_extractor_func mengembalikan list saat error, tangani:\n",
    "        if isinstance(features_data, list):\n",
    "            if not features_data: # Jika list kosong\n",
    "                logger.error(f\"Gagal mengekstrak fitur (list kosong) untuk URL: {url}\")\n",
    "                return \"Error\", None, []\n",
    "            else:\n",
    "                # Jika list tidak kosong, coba konversi ke DataFrame.\n",
    "                # Asumsi list berisi dictionary atau list of lists yang sesuai.\n",
    "                # Ini mungkin perlu penyesuaian berdasarkan apa yang dikembalikan oleh extract_features Anda saat error.\n",
    "                try:\n",
    "                    # Jika extract_features mengembalikan list of dicts [{feature: value, ...}]\n",
    "                    # atau list of values [[value1, value2, ...]] yang perlu nama kolom\n",
    "                    # Anda perlu tahu nama kolom yang diharapkan.\n",
    "                    # Untuk contoh, asumsikan ia mengembalikan list nilai fitur dan Anda punya feature_names_expected\n",
    "                    # features_df = pd.DataFrame([features_data], columns=feature_names_expected_if_error)\n",
    "                    # Lebih aman, jika dia mengembalikan list saat error, anggap saja error.\n",
    "                    logger.error(f\"Ekstraksi fitur mengembalikan list, bukan DataFrame, untuk URL: {url}. Data: {features_data}\")\n",
    "                    return \"Error\", None, []\n",
    "                except Exception as e_conv:\n",
    "                    logger.error(f\"Gagal mengonversi hasil ekstraksi fitur (list) ke DataFrame untuk URL '{url}': {e_conv}\")\n",
    "                    return \"Error\", None, []\n",
    "        elif not isinstance(features_data, pd.DataFrame):\n",
    "             logger.error(f\"Ekstraksi fitur tidak mengembalikan DataFrame untuk URL: {url}. Tipe: {type(features_data)}\")\n",
    "             return \"Error\", None, []\n",
    "        \n",
    "        features_df = features_data # Sekarang features_df pasti DataFrame jika lolos pengecekan\n",
    "\n",
    "        if features_df.empty: # Sekarang .empty aman digunakan\n",
    "            logger.error(f\"DataFrame fitur kosong untuk URL: {url}\")\n",
    "            return \"Error\", None, []\n",
    "\n",
    "        feature_names = list(features_df.columns)\n",
    "        feature_values_dict = features_df.iloc[0].to_dict() # Nilai fitur asli sebelum preprocessing\n",
    "\n",
    "        # 2. Preprocessing (jika ada)\n",
    "        if preprocessor_obj:\n",
    "            # Penting: Pastikan preprocessor tidak mengubah urutan/jumlah fitur\n",
    "            # atau Anda memiliki cara untuk memetakan kembali nama fitur.\n",
    "            # Untuk scaler standar, urutan dan jumlah biasanya tetap.\n",
    "            processed_features = preprocessor_obj.transform(features_df)\n",
    "        else:\n",
    "            processed_features = features_df.values # Model mungkin dilatih dengan DataFrame langsung\n",
    "\n",
    "        # 3. Prediksi\n",
    "        proba = None\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            proba_all = model.predict_proba(processed_features)\n",
    "            # Asumsi kelas phishing adalah kelas 1 (indeks 1)\n",
    "            # Jika kelas phishing adalah 0, ubah menjadi proba_all[0][0]\n",
    "            if proba_all.shape[1] > 1:\n",
    "                 probability_phishing = proba_all[0][1]\n",
    "            else: # Untuk model seperti SVM dengan probability=True yang outputnya (n_samples,) untuk binary\n",
    "                 probability_phishing = proba_all[0]\n",
    "        elif hasattr(model, 'decision_function'): # Untuk model seperti SVC tanpa predict_proba\n",
    "            decision_val = model.decision_function(processed_features)\n",
    "            # Perlu dikonversi ke probabilitas jika memungkinkan, atau gunakan decision value\n",
    "            # Untuk simplisitas, kita bisa set probability_phishing berdasarkan ini jika perlu\n",
    "            # atau biarkan None jika tidak langsung tersedia.\n",
    "            # Ini contoh sederhana, mungkin perlu kalibrasi\n",
    "            probability_phishing = 1 / (1 + np.exp(-decision_val[0])) if decision_val is not None else None\n",
    "        else: # Model hanya punya .predict()\n",
    "            probability_phishing = None # Atau coba dapatkan dari predict jika outputnya probabilitas\n",
    "\n",
    "        # Dapatkan prediksi label\n",
    "        if probability_phishing is not None:\n",
    "            predicted_label = 1 if probability_phishing >= threshold else 0\n",
    "        else: # Jika tidak ada probabilitas, gunakan predict langsung\n",
    "            predicted_label = model.predict(processed_features)[0]\n",
    "\n",
    "\n",
    "        predicted_type = \"Phishing\" if predicted_label == 1 else \"Aman\" # Sesuaikan dengan encoding label Anda\n",
    "\n",
    "        # 4. Dapatkan Bobot/Kepentingan Fitur\n",
    "        importances = None\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Untuk klasifikasi biner, coef_ seringkali (1, n_features) atau (n_features,)\n",
    "            importances = model.coef_[0] if model.coef_.ndim > 1 else model.coef_\n",
    "\n",
    "        feature_details_list = []\n",
    "        if importances is not None and len(importances) == len(feature_names):\n",
    "            for name, value, importance_val in zip(feature_names, features_df.iloc[0], importances):\n",
    "                feature_details_list.append({'name': name, 'value': value, 'importance': importance_val})\n",
    "            # Urutkan berdasarkan nilai absolut kepentingan untuk menunjukkan fitur paling berpengaruh\n",
    "            feature_details_list.sort(key=lambda x: abs(x['importance']), reverse=True)\n",
    "        else:\n",
    "            # Fallback jika tidak ada atribut importance atau panjang tidak cocok: hanya tampilkan nama dan nilai fitur\n",
    "            for name, value in feature_values_dict.items(): # Gunakan nilai asli\n",
    "                feature_details_list.append({'name': name, 'value': value, 'importance': 'N/A (tidak tersedia dari model)'})\n",
    "            if importances is not None and len(importances) != len(feature_names):\n",
    "                logger.warning(\"Jumlah bobot fitur dari model tidak cocok dengan jumlah fitur yang diekstrak.\")\n",
    "\n",
    "\n",
    "        return predicted_type, probability_phishing, feature_details_list\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saat memprediksi URL '{url}': {e}\", exc_info=True)\n",
    "        return \"Error\", None, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b32cfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Mode Inferensi URL Tunggal ---\n",
      "Ketik 'exit' atau 'quit' untuk keluar.\n",
      "2025-06-02 11:13:58 - __main__ - INFO - Memproses URL: https://calendar.google.com/calendar/u/3/r\n",
      "2025-06-02 11:13:58 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://calendar.google.com/calendar/u/3/r\n",
      "2025-06-02 11:13:59 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://calendar.google.com/calendar/u/3/r. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "2025-06-02 11:13:59 - __main__ - INFO - Prediksi untuk 'https://calendar.google.com/calendar/u/3/r': Tipe='Aman', Prob_Phishing=0.0323 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://calendar.google.com/calendar/u/3/r':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0323\n",
      "2025-06-02 11:14:03 - __main__ - INFO - Memproses URL: https://www.notion.so/fahmidza/Capstone-Project-1ce748923a5880a28875da6caabf7cec\n",
      "2025-06-02 11:14:03 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://www.notion.so/fahmidza/Capstone-Project-1ce748923a5880a28875da6caabf7cec\n",
      "2025-06-02 11:14:04 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://www.notion.so/fahmidza/Capstone-Project-1ce748923a5880a28875da6caabf7cec. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "2025-06-02 11:14:04 - __main__ - INFO - Prediksi untuk 'https://www.notion.so/fahmidza/Capstone-Project-1ce748923a5880a28875da6caabf7cec': Tipe='Aman', Prob_Phishing=0.0488 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://www.notion.so/fahmidza/Capstone-Project-1ce748923a5880a28875da6caabf7cec':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0488\n",
      "2025-06-02 11:14:08 - __main__ - INFO - Memproses URL: https://cekresi.com/\n",
      "2025-06-02 11:14:08 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://cekresi.com/\n",
      "2025-06-02 11:14:09 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://cekresi.com/. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "2025-06-02 11:14:09 - __main__ - INFO - Prediksi untuk 'https://cekresi.com/': Tipe='Aman', Prob_Phishing=0.0277 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://cekresi.com/':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0277\n",
      "2025-06-02 11:14:14 - __main__ - INFO - Memproses URL: https://simaster.ugm.ac.id/\n",
      "2025-06-02 11:14:14 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://simaster.ugm.ac.id/\n",
      "2025-06-02 11:14:15 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://simaster.ugm.ac.id/. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "2025-06-02 11:14:15 - __main__ - INFO - Prediksi untuk 'https://simaster.ugm.ac.id/': Tipe='Aman', Prob_Phishing=0.0520 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://simaster.ugm.ac.id/':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0520\n",
      "2025-06-02 11:14:25 - __main__ - INFO - Memproses URL: https://www.dicoding.com/academies/319/corridor\n",
      "2025-06-02 11:14:25 - FeatureExtractor - INFO - Memulai ekstraksi fitur untuk URL: https://www.dicoding.com/academies/319/corridor\n",
      "2025-06-02 11:14:26 - FeatureExtractor - INFO - Selesai ekstraksi fitur untuk URL: https://www.dicoding.com/academies/319/corridor. Total fitur: 21\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "2025-06-02 11:14:26 - __main__ - INFO - Prediksi untuk 'https://www.dicoding.com/academies/319/corridor': Tipe='Aman', Prob_Phishing=0.0445 (Threshold: 0.5)\n",
      "--> Hasil Prediksi untuk 'https://www.dicoding.com/academies/319/corridor':\n",
      "    Tipe Terdeteksi: Aman\n",
      "    Probabilitas (Phishing): 0.0445\n",
      "2025-06-02 11:14:33 - __main__ - INFO - Keluar dari mode inferensi.\n"
     ]
    }
   ],
   "source": [
    "# Sel 4: Loop Interaktif untuk Input Pengguna\n",
    "\n",
    "if 'loaded_model' in locals() and loaded_model: # Pastikan model sudah dimuat dari Sel 2\n",
    "    print(\"\\n--- Mode Inferensi URL Tunggal ---\")\n",
    "    print(\"Ketik 'exit' atau 'quit' untuk keluar.\")\n",
    "    while True:\n",
    "        user_url = input(\"\\nMasukkan URL yang ingin Anda periksa: \").strip()\n",
    "        if user_url.lower() in ['exit', 'quit']:\n",
    "            logger.info(\"Keluar dari mode inferensi.\")\n",
    "            break\n",
    "        if not user_url:\n",
    "            print(\"URL tidak boleh kosong. Silakan coba lagi.\")\n",
    "            continue\n",
    "\n",
    "        # Panggil fungsi prediksi dari Sel 3\n",
    "        # 'extract_features' sudah diimpor secara global di Sel 1\n",
    "        # 'preprocessor' adalah objek yang dimuat di Sel 2 (bisa None)\n",
    "        # 'loaded_model' adalah model yang dimuat di Sel 2\n",
    "        \n",
    "        # TODO: Tentukan threshold yang optimal dari eksperimen Anda jika model outputnya sigmoid\n",
    "        prediction_threshold = 0.5 \n",
    "\n",
    "        predicted_type, probability = predict_url_type(\n",
    "            user_url,\n",
    "            loaded_model, \n",
    "            preprocessor_obj=preprocessor, # Akan bernilai None jika tidak ada preprocessor dimuat\n",
    "            threshold=prediction_threshold \n",
    "        )\n",
    "\n",
    "        if predicted_type is not None:\n",
    "            print(f\"--> Hasil Prediksi untuk '{user_url}':\")\n",
    "            print(f\"    Tipe Terdeteksi: {predicted_type}\")\n",
    "            if probability is not None:\n",
    "                print(f\"    Probabilitas (Phishing): {probability:.4f}\")\n",
    "        else:\n",
    "            print(f\"--> Tidak dapat membuat prediksi untuk '{user_url}'. Periksa log untuk detail.\")\n",
    "else:\n",
    "    print(\"Model belum dimuat (variabel 'loaded_model' tidak ditemukan atau None). Jalankan Sel 2 terlebih dahulu.\")\n",
    "    logger.error(\"Inferensi tidak bisa dijalankan karena model belum dimuat.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
